import requests
import json
import os
import time
import html2text
import re
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# --- è¨­å®š ---
USER_ID = "mujihayashi_note"
OUTPUT_DIR = f"./{USER_ID}_articles"

def get_all_notes_info(user_id):
    """æŒ‡å®šã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¨è¨˜äº‹ã‚­ãƒ¼ã¨ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã®æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚"""
    all_notes = {}
    page = 1
    print("å…¨è¨˜äº‹ã®åŸºæœ¬æƒ…å ±ï¼ˆã‚­ãƒ¼ã€ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ï¼‰ã®å–å¾—ã‚’é–‹å§‹ã—ã¾ã™...")
    while True:
        try:
            print(f"{page}ãƒšãƒ¼ã‚¸ç›®ã®è¨˜äº‹ä¸€è¦§ã‚’å–å¾—ä¸­...")
            url = f"https://note.com/api/v2/creators/{user_id}/contents?kind=note&page={page}"
            res = requests.get(url, timeout=10)
            res.raise_for_status()
            data = res.json()["data"]

            if not data["contents"]:
                break

            for content in data["contents"]:
                key = content.get("key")
                if key:
                    hashtags = [tag["hashtag"]["name"] for tag in content.get("hashtags", []) if "hashtag" in tag and tag.get("hashtag")]
                    all_notes[key] = {"hashtags": hashtags}

            if data["isLastPage"]:
                break
            page += 1
            time.sleep(3)
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: è¨˜äº‹ä¸€è¦§ã®å–å¾—ä¸­ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ {e}")
            return None
    print("ã™ã¹ã¦ã®åŸºæœ¬æƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
    return all_notes

def get_note_detail(note_key):
    """èªè¨¼æƒ…å ±ã‚’ä½¿ã£ã¦ã€æŒ‡å®šã•ã‚ŒãŸã‚­ãƒ¼ã®noteè¨˜äº‹è©³ç´°ã‚’å–å¾—ã—ã¾ã™ã€‚"""
    token1 = os.getenv("NOTE_GQL_AUTH_TOKEN")
    token2 = os.getenv("_NOTE_SESSION_V5")

    cookies = {}
    if token1 and token2:
        cookies['note_gql_auth_token'] = token1
        cookies['_note_session_v5'] = token2
    else:
        print("è­¦å‘Š: .envãƒ•ã‚¡ã‚¤ãƒ«ã«å¿…è¦ãªèªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç„¡æ–™éƒ¨åˆ†ã®ã¿å–å¾—ã—ã¾ã™ã€‚")

    try:
        url = f"https://note.com/api/v3/notes/{note_key}"
        res = requests.get(url, timeout=10, cookies=cookies)
        res.raise_for_status()
        return res.json()["data"]
    except Exception as e:
        print(f"    -> ã‚¨ãƒ©ãƒ¼: è¨˜äº‹è©³ç´°ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ {note_key}, {e}")
        return None

def create_related_article_card(note_data):
    """å–å¾—ã—ãŸè¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å†…éƒ¨ãƒ»å¤–éƒ¨ãƒªãƒ³ã‚¯ä»˜ãã®Markdownã‚«ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¾ã™ã€‚"""
    title = note_data.get("name", "ç„¡é¡Œ")
    note_key = note_data.get("key")
    external_url = note_data.get("note_url", "")
    eyecatch = note_data.get("eyecatch", "")
    
    # å†…éƒ¨ãƒªãƒ³ã‚¯ç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
    safe_title = re.sub(r'[\/:"*?<>|]+', "_", title)
    internal_link = f"{note_key}_{safe_title}"

    description = note_data.get("description", "")
    if not description and "body" in note_data:
        clean_body = re.sub("<.*?>", "", note_data["body"]).replace('\n', ' ').strip()
        description = clean_body[:100] + '...' if len(clean_body) > 100 else clean_body

    user_name = note_data.get("user", {}).get("nickname", "")
    publish_date = note_data.get("publish_at", "")[:10]

    card = f"""
> ---
> ### [{title}]({internal_link}) [ğŸŒ]({external_url})\n"""
    if eyecatch:
        card += f"> ![thumbnail]({eyecatch})\n"
    card += f">\n> {description}\n>\n"
    if user_name and publish_date:
        card += f"> *{user_name} - {publish_date}*\n"
    card += "> ---"
    return card

def save_as_markdown(note_key, note_info, output_dir):
    """è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã€Markdownãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚"""
    try:
        note_detail = get_note_detail(note_key)
        if not note_detail:
            return

        title = note_detail.get("name", "ç„¡é¡Œ")
        eyecatch_url = note_detail.get("eyecatch")
        body_html = note_detail.get("body", "")
        
        hashtags_from_list = note_info.get("hashtags", [])
        hashtags_from_detail = [t["hashtag"]["name"] for t in note_detail.get("hashtag_notes", []) if "hashtag" in t and t.get("hashtag")]
        hashtags = sorted(list(set(hashtags_from_list + hashtags_from_detail)))

        soup = BeautifulSoup(body_html, "html.parser")
        for figure in soup.find_all("figure", attrs={"embedded-service": "note"}):
            related_key = figure.get("data-identifier")
            if not related_key or related_key == note_key: continue

            print(f"    -> é–¢é€£è¨˜äº‹ãƒªãƒ³ã‚¯ç™ºè¦‹: {related_key}ã€‚è©³ç´°ã‚’å–å¾—ä¸­...")
            time.sleep(3)
            related_detail = get_note_detail(related_key)

            if related_detail:
                card_md = create_related_article_card(related_detail)
                figure.replace_with(card_md)

        h = html2text.HTML2Text()
        h.body_width = 0
        body_md = h.handle(str(soup))

        md_content = f"# {title}\n\n"
        if eyecatch_url:
            md_content += f"![eyecatch]({eyecatch_url})\n\n"
        md_content += "---\n\n"
        md_content += body_md

        if hashtags:
            md_content += "\n\n---\n\n## ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°\n"
            for tag in hashtags:
                md_content += f"- {tag}\n"

        safe_title = re.sub(r'[\/:"*?<>|]+', "_", title)
        file_name = f"{note_key}_{safe_title}.md"
        file_path = os.path.join(output_dir, file_name)

        with open(file_path, "w", encoding="utf-8") as f:
            f.write(md_content)
        print(f"  -> å®Œäº†: {file_path}")

    except Exception as e:
        print(f"  -> ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ {note_key}, {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    ARTICLE_LIMIT = 0 # 0ã§å…¨ä»¶å–å¾—

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    print(f"è¨˜äº‹ã®ä¿å­˜å…ˆ: {os.path.abspath(OUTPUT_DIR)}")

    all_notes_info = get_all_notes_info(USER_ID)

    if not all_notes_info:
        print("è¨˜äº‹æƒ…å ±ãŒå–å¾—ã§ããªã‹ã£ãŸãŸã‚ã€å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        return

    note_keys = list(all_notes_info.keys())
    if ARTICLE_LIMIT > 0:
        print(f"\nâ˜…â˜…â˜… ãŠè©¦ã—ãƒ¢ãƒ¼ãƒ‰: æœ€æ–°ã®{ARTICLE_LIMIT}ä»¶ã®ã¿å–å¾—ã—ã¾ã™ â˜…â˜…â˜…\n")
        note_keys = note_keys[:ARTICLE_LIMIT]

    total_notes = len(note_keys)
    print(f"\nåˆè¨ˆ{total_notes}ä»¶ã®è¨˜äº‹ã‚’å‡¦ç†ã—ã¾ã™ã€‚")
    for i, note_key in enumerate(note_keys):
        print(f"({i + 1}/{total_notes}) è¨˜äº‹ã‚’å‡¦ç†ä¸­: {note_key}")
        note_info = all_notes_info.get(note_key, {})
        save_as_markdown(note_key, note_info, OUTPUT_DIR)
        time.sleep(3)

    print("\nã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()